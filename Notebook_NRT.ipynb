{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb525c62-ebef-43e4-be6a-c83288f3ce31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, IntegerType, StringType, DoubleType\n",
    "import json\n",
    "\n",
    "# 1. Cargar Archivo\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# 2. inicializaer Variables\n",
    "kafka_bootstrap_servers = config[\"kafka\"][\"bootstrap_servers\"]\n",
    "kafka_topic = config[\"kafka\"][\"topic\"]\n",
    "kafka_sasl_username = config[\"kafka\"][\"username\"]\n",
    "kafka_sasl_password = config[\"kafka\"][\"password\"]\n",
    "\n",
    "mongo_uri = config[\"mongodb\"][\"uri\"]\n",
    "mongo_db = config[\"mongodb\"][\"database\"]\n",
    "mongo_collection = config[\"mongodb\"][\"collection\"]\n",
    "\n",
    "# 3. Crear sesi√≥n de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaToMongoBatchJob\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,\" \n",
    "            \"org.mongodb.spark:mongo-spark-connector_2.12:10.1.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 4. Definir esquema del mensaje Kafka\n",
    "schema = StructType() \\\n",
    "    .add(\"Id\", IntegerType()) \\\n",
    "    .add(\"ClienteId\", StringType()) \\\n",
    "    .add(\"Monto\", DoubleType()) \\\n",
    "    .add(\"FechaPago\", StringType()) \\\n",
    "    .add(\"MetodoPago\", StringType()) \\\n",
    "    .add(\"Estado\", StringType())\n",
    "\n",
    "# 5. Leer mensajes desde Kafka (modo streaming)\n",
    "kafka_options = {\n",
    "    \"kafka.bootstrap.servers\": kafka_bootstrap_servers,\n",
    "    \"subscribe\": kafka_topic,\n",
    "    \"kafka.security.protocol\": \"SASL_SSL\",\n",
    "    \"kafka.sasl.mechanism\": \"PLAIN\",\n",
    "    \"kafka.sasl.jaas.config\": f'org.apache.kafka.common.security.plain.PlainLoginModule required username=\"{kafka_sasl_username}\" password=\"{kafka_sasl_password}\";',\n",
    "    \"startingOffsets\": \"earliest\"\n",
    "}\n",
    "df_kafka_streaming = spark.readStream.format(\"kafka\").options(**kafka_options).load()\n",
    "df_kafka_raw = df_kafka_streaming\n",
    "\n",
    "# 6. Convertir 'value' a string y parsear JSON con el esquema\n",
    "df_parsed = df_kafka_raw.select(\n",
    "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")\n",
    ")\n",
    "\n",
    "# 7. Seleccionar campos del struct 'data' para mostrar columnas separadas\n",
    "df_final = df_parsed.select(\"data.*\")\n",
    "\n",
    "# 8. Renombrar la columna 'Id' a '_id'\n",
    "df_mongo = df_final.withColumnRenamed(\"Id\", \"_id\")\n",
    "df_mongo.display()\n",
    "\n",
    "# 9. Escribir en MongoDB Atlas\n",
    "df_mongo.writeStream   \\\n",
    "    .format(\"mongodb\") \\\n",
    "    .option(\"spark.mongodb.connection.uri\", mongo_uri) \\\n",
    "    .option(\"spark.mongodb.database\", mongo_db) \\\n",
    "    .option(\"spark.mongodb.collection\", mongo_collection) \\\n",
    "    .option(\"checkpointLocation\", \"dbfs:/mnt/checkpoints/pagos_nrt\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "\n",
    "#.option(\"checkpointLocation\", \"/tmp/checkpoint_pagos\") \\"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook_NRT",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
